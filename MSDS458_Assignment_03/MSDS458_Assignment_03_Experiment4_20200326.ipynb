{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "DATE: March 26, 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 3:\n",
    "\n",
    "The goal is to compare several NLP algorithms for Reuters data – multi-class classification problem\n",
    " \n",
    "First, do EDA to understand how many topics (classes) are there in the data. Also understand how many documents\n",
    "are there in each class. You may want to reduce the number of topics to top 10 or something like that, based\n",
    "on frequencies.  \n",
    "\n",
    "In all the experiments, we would hold some parameters constants – truncation of the documents to 128 tokens,\n",
    " the batch size to 100, the number of epochs to 10, same optimizer, same loss function of cross entropy, so that\n",
    " the comparisons are fair.\n",
    " \n",
    "* EXPERIMENT 1: Fully connected dense neural network\n",
    "* EXPERIMENT 2: Simple RNN\n",
    "* EXPERIMENT 3: LSTM RNN\n",
    "* **EXPERIMENT 4: 1D CNN**\n",
    "\n",
    "`Result`:  Create a table with the accuracy and loss for train/test/validation & process time for all the 4 models.\n",
    "\n",
    "`Note`: You can tweak several parameters such as dropout, embedding etc. to get more insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.4-tf'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Reuters dataset\n",
    "\n",
    "\n",
    "We will be working with the `Reuters dataset`, a set of short newswires and their topics, published by Reuters in 1986. It's a very simple, \n",
    "widely used toy dataset for text classification. There are 46 different topics; some topics are more represented than others, but each \n",
    "topic has at least 10 examples in the training set.\n",
    "\n",
    "Like IMDB and MNIST, the Reuters dataset comes packaged as part of Keras. Let's take a look right away:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://keras.io/datasets/#reuters-newswire-topics-classification\n",
    "from tensorflow.keras.datasets import reuters\n",
    "\n",
    "(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The argument `num_words=128` restricts the data to the 128 most frequently occurring words found in the data.\n",
    "\n",
    "We have 8,982 training examples and 2,246 test examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8982, 8982, 2246, 2246)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data), len(train_labels), len(test_data), len(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reducing the number of topics"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Let's get the frequency distribution of topics in both the training and test data to get data for the most popular topics, say the \"top 10\". In fact, we settle for the top 9 since those are the same for both training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 4, 19, 16, 1, 11, 20, 13, 8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "topics_train_tpl, _ = zip(*Counter(list(train_labels)).most_common(9))\n",
    "topics_train_tpl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 4, 19, 1, 16, 11, 20, 8, 13)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics_test_tpl, _ = zip(*Counter(list(test_labels)).most_common(9))\n",
    "topics_test_tpl"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Get the training labels which are in topics_train_tpl = topics_test_tpl and the corresponding training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_sm, train_labels_sm = zip(*((x,y) for x,y in zip(train_data,train_labels) if y in topics_train_tpl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "train_data_sm, train_labels_sm = np.array(train_data_sm), np.array(train_labels_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7503, 7503)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data_sm), len(train_labels_sm)  # matches number of training values in top 10"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Get the test labels which are in topics_test_tpl = topics_train_tpl and the corresponding test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_sm, test_labels_sm = zip(*((x,y) for x,y in zip(test_data,test_labels) if y in topics_test_tpl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_sm, test_labels_sm = np.array(test_data_sm), np.array(test_labels_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1852, 1852)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data_sm), len(test_labels_sm) # matches number of test values in top 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({3: 3159,\n",
       "         4: 1949,\n",
       "         16: 444,\n",
       "         19: 549,\n",
       "         8: 139,\n",
       "         11: 390,\n",
       "         1: 432,\n",
       "         13: 172,\n",
       "         20: 269})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(train_labels_sm) # another sanity check on the the new smaller set of training labels. See In [13]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({3: 813,\n",
       "         1: 105,\n",
       "         4: 474,\n",
       "         11: 83,\n",
       "         19: 133,\n",
       "         8: 38,\n",
       "         20: 70,\n",
       "         16: 99,\n",
       "         13: 37})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(test_labels_sm) # another sanity check on the the new smaller set of test labels. See In [14]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### EXPERIMENT 4: 1D CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the data\n",
    "\n",
    "We need to vectorize the sequence into numeric tensors that the neural networks can work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7503,), (1852,))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_sm.shape, test_data_sm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# def vectorize_sequences(sequences, dimension=10000):\n",
    "#     results = np.zeros((len(sequences), dimension))\n",
    "#     for i, sequence in enumerate(sequences):\n",
    "#         results[i, sequence] = 1.\n",
    "#     return results\n",
    "\n",
    "# # Our vectorized training data\n",
    "# train_data_smv = vectorize_sequences(train_data_sm)\n",
    "# # Our vectorized test data\n",
    "# test_data_smv = vectorize_sequences(test_data_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternate processing for RNN...\n",
    "# https://github.com/fchollet/deep-learning-with-python-notebooks/blob/master/6.1-using-word-embeddings.ipynb\n",
    "\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras import preprocessing\n",
    "\n",
    "train_data_sm_rnn = preprocessing.sequence.pad_sequences(train_data_sm, maxlen=30)\n",
    "test_data_sm_rnn = preprocessing.sequence.pad_sequences(test_data_sm, maxlen=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "one_hot_train_labels_sm = to_categorical(train_labels_sm)\n",
    "one_hot_test_labels_sm = to_categorical(test_labels_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7503,), (7503, 21))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels_sm.shape, one_hot_train_labels_sm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1852, 30), (7503, 30), (7503, 21), (1852, 21))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_sm_rnn.shape, train_data_sm_rnn.shape, one_hot_train_labels_sm.shape, one_hot_test_labels_sm.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building our network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Embedding, LSTM\n",
    "# from tensorflow.keras.layers import Dense\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(Embedding(10000, 64))\n",
    "# model.add(LSTM(32))\n",
    "# model.add(Dense(21, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 30, 64)            640000    \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 28, 32)            6176      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               459264    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 21)                10773     \n",
      "=================================================================\n",
      "Total params: 1,116,213\n",
      "Trainable params: 1,116,213\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# https://github.com/jsrpy/NLP_Sentiment_Analysis/blob/master/Reuters_news_topic_classify_A.ipynb\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, Embedding, Dropout\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(10000, 64, input_length=30))\n",
    "model.add(Conv1D(32,3, activation='relu')) #\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu')) #\n",
    "model.add(Dropout(0.5)) #\n",
    "model.add(Dense(21, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras.backend.clear_session()\n",
    "\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras import layers\n",
    "# from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(layers.Embedding(10000, 128, input_length=100))\n",
    "# model.add(layers.Conv1D(32, 7, activation='relu'))\n",
    "# model.add(layers.MaxPooling1D(5))\n",
    "# model.add(layers.Conv1D(32, 7, activation='relu'))\n",
    "# model.add(layers.GlobalMaxPooling1D())\n",
    "# model.add(layers.Dense(21))\n",
    "\n",
    "# model.summary()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(optimizer=RMSprop(lr=1e-4),\n",
    "#               loss='categorical_crossentropy',\n",
    "#               metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validating our approach\n",
    "\n",
    "In the commented code below we set apart 1,000 samples in our training data to use as a validation set. Instead, we set the validation_split (=0.15) when training the model.As an alternative, you can uncomment this code and uncomment: validation_data=(val_data_smv, one_hot_val_labels_sm))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_data_sm_rnn = train_data_sm_rnn[:1000]\n",
    "# train_data_sm_rnn = train_data_sm_rnn[1000:]\n",
    "\n",
    "# one_hot_val_labels_sm = one_hot_train_labels_sm[:1000]\n",
    "# one_hot_train_labels_sm = one_hot_train_labels_sm[1000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data_sm_rnn.shape, train_data_sm_rnn.shape, one_hot_train_labels_sm.shape, one_hot_test_labels_sm.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model\n",
    "\n",
    "To get the total training time I used the callback. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define callback to get total training time\n",
    "import datetime\n",
    "\n",
    "class TrainRuntimeCallback(keras.callbacks.Callback):\n",
    "\n",
    "  def on_train_begin(self,logs={}):\n",
    "    self.start = datetime.datetime.now()\n",
    "\n",
    "  def on_train_end(self,logs={}):\n",
    "    self.process_time = (datetime.datetime.now() - self.start).total_seconds()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's train our network for 10 epochs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6377 samples, validate on 1126 samples\n",
      "Epoch 1/10\n",
      "6377/6377 [==============================] - 2s 374us/sample - loss: 1.6522 - accuracy: 0.4872 - val_loss: 1.3445 - val_accuracy: 0.5684\n",
      "Epoch 2/10\n",
      "6377/6377 [==============================] - 2s 273us/sample - loss: 1.2622 - accuracy: 0.5815 - val_loss: 1.2069 - val_accuracy: 0.5853\n",
      "Epoch 3/10\n",
      "6377/6377 [==============================] - 2s 271us/sample - loss: 1.1776 - accuracy: 0.5945 - val_loss: 1.1463 - val_accuracy: 0.6101\n",
      "Epoch 4/10\n",
      "6377/6377 [==============================] - 2s 270us/sample - loss: 1.1046 - accuracy: 0.6284 - val_loss: 1.1091 - val_accuracy: 0.6261\n",
      "Epoch 5/10\n",
      "6377/6377 [==============================] - 2s 271us/sample - loss: 1.0441 - accuracy: 0.6516 - val_loss: 1.1157 - val_accuracy: 0.6226\n",
      "Epoch 6/10\n",
      "6377/6377 [==============================] - 2s 275us/sample - loss: 0.9811 - accuracy: 0.6716 - val_loss: 1.0677 - val_accuracy: 0.6394\n",
      "Epoch 7/10\n",
      "6377/6377 [==============================] - 2s 272us/sample - loss: 0.9167 - accuracy: 0.6922 - val_loss: 1.0669 - val_accuracy: 0.6474\n",
      "Epoch 8/10\n",
      "6377/6377 [==============================] - 2s 264us/sample - loss: 0.8539 - accuracy: 0.7206 - val_loss: 1.0669 - val_accuracy: 0.6456\n",
      "Epoch 9/10\n",
      "6377/6377 [==============================] - 2s 267us/sample - loss: 0.7911 - accuracy: 0.7413 - val_loss: 1.1069 - val_accuracy: 0.6403\n",
      "Epoch 10/10\n",
      "6377/6377 [==============================] - 2s 270us/sample - loss: 0.7362 - accuracy: 0.7563 - val_loss: 1.0963 - val_accuracy: 0.6448\n"
     ]
    }
   ],
   "source": [
    "train_rt = TrainRuntimeCallback()\n",
    "history = model.fit(train_data_sm_rnn, one_hot_train_labels_sm,\n",
    "                    callbacks = [train_rt],\n",
    "                    epochs=10,\n",
    "                    batch_size=100,\n",
    "                    validation_split=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_rt = TrainRuntimeCallback()\n",
    "# history = model.fit(train_data_sm_rnn,\n",
    "#                     one_hot_train_labels_sm,\n",
    "#                     callbacks = [train_rt],\n",
    "#                     epochs=10,\n",
    "#                     batch_size=100,\n",
    "# #                   validation_data=(val_data_sm_rnn, one_hot_val_labels_sm))\n",
    "#                     validation_split = 0.15)   # comment out if setting validation_data value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.91159"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the training time\n",
    "train_time = train_rt.process_time\n",
    "train_time # in seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the model\n",
    "\n",
    "Test the model and get its runtime using callbacks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define callback to get total test time\n",
    "import datetime\n",
    "\n",
    "class TestRuntimeCallback(keras.callbacks.Callback):\n",
    "\n",
    "  def on_test_begin(self,logs={}):\n",
    "    self.start = datetime.datetime.now()\n",
    "\n",
    "  def on_test_end(self,logs={}):\n",
    "    self.process_time = (datetime.datetime.now() - self.start).total_seconds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1852/1852 [==============================] - 0s 124us/sample - loss: 1.1091 - accuracy: 0.6442\n"
     ]
    }
   ],
   "source": [
    "test_rt = TestRuntimeCallback()\n",
    "# test_loss, test_acc = model.evaluate(test_data_sm_rnn, one_hot_test_labels_sm, callbacks=[test_rt])\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(test_data_sm_rnn, one_hot_test_labels_sm, callbacks=[test_rt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23003"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the test time\n",
    "test_time = test_rt.process_time\n",
    "test_time # in seconds"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Use the history to get the rest of the statistics we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'val_loss', 'val_accuracy', 'train_accuracy'])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "history_dict['train_accuracy'] = history_dict.pop('accuracy') # rename the the key to 'test_accuracy'\n",
    "history_dict.keys()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Note that we have has stats after each epoch..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>train_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.981142</td>\n",
       "      <td>1.067737</td>\n",
       "      <td>0.639432</td>\n",
       "      <td>0.671632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.916715</td>\n",
       "      <td>1.066873</td>\n",
       "      <td>0.647425</td>\n",
       "      <td>0.692175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.853888</td>\n",
       "      <td>1.066898</td>\n",
       "      <td>0.645648</td>\n",
       "      <td>0.720558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.791087</td>\n",
       "      <td>1.106907</td>\n",
       "      <td>0.640320</td>\n",
       "      <td>0.741258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.736178</td>\n",
       "      <td>1.096277</td>\n",
       "      <td>0.644760</td>\n",
       "      <td>0.756312</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       loss  val_loss  val_accuracy  train_accuracy\n",
       "5  0.981142  1.067737      0.639432        0.671632\n",
       "6  0.916715  1.066873      0.647425        0.692175\n",
       "7  0.853888  1.066898      0.645648        0.720558\n",
       "8  0.791087  1.106907      0.640320        0.741258\n",
       "9  0.736178  1.096277      0.644760        0.756312"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "history_df=pd.DataFrame(history_dict)\n",
    "history_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the performance to a DataFrame\n",
    "\n",
    "Let us now create the DataFrame with statistics which we append to the DataFrame from part 2. Note that we only need the last row of `history_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>loss</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>training time (sec)</th>\n",
       "      <th>testing time (sec)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1D CNN</td>\n",
       "      <td>0.736178</td>\n",
       "      <td>1.096277</td>\n",
       "      <td>0.64476</td>\n",
       "      <td>0.756312</td>\n",
       "      <td>0.644168</td>\n",
       "      <td>17.91159</td>\n",
       "      <td>0.23003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    model      loss  val_loss  val_accuracy  train_accuracy  test_accuracy  \\\n",
       "9  1D CNN  0.736178  1.096277       0.64476        0.756312       0.644168   \n",
       "\n",
       "   training time (sec)  testing time (sec)  \n",
       "9             17.91159             0.23003  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = history_df.iloc[-1:].copy()\n",
    "results_df.insert(0,'model','1D CNN') # went the model name to appear first\n",
    "results_df['test_accuracy'] = test_accuracy\n",
    "results_df['training time (sec)'] = train_time      # we are okay with training time appearing last\n",
    "results_df['testing time (sec)'] = test_time      # we are okay with training time appearing last\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'results3.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-a3a0666e1866>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprev_results_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'results3.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mresults_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprev_results_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mresults_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36mread_pickle\u001b[0;34m(filepath_or_buffer, compression)\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcompression\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"infer\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0mcompression\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m     \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0;31m# 1) try standard library Pickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text)\u001b[0m\n\u001b[1;32m    432\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'results3.pkl'"
     ]
    }
   ],
   "source": [
    "prev_results_df = pd.read_pickle('results3.pkl')\n",
    "results_df = prev_results_df.append(results_df,ignore_index=True)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_pickle(\"results4.pkl\") # save the DataFrame to use in Part 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()   # clear figure\n",
    "\n",
    "acc = history.history['train_accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our approach reaches an accuracy of ~85%. With a balanced binary classification problem, the accuracy reached by a purely random classifier \n",
    "would be 50%, but in our case it is closer to 26%, so our results seem pretty good, at least when compared to a random baseline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "test_labels_sm_copy = copy.copy(test_labels_sm)\n",
    "np.random.shuffle(test_labels_sm_copy)\n",
    "float(np.sum(np.array(test_labels_sm) == np.array(test_labels_sm_copy))) / len(test_labels_sm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving to a DataFrame to disk\n",
    "\n",
    "Save the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_pickle(\"results4.pkl\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
